{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook para la conversi贸n de db sqlite to pg**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 0: Inicializacion - Definici贸n de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Importacion de librerias*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as al\n",
    "from configparser import ConfigParser\n",
    "import pandas.io.sql as sqlio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Configuraciones*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para la eExtraccion de parametros del archivo 'PGToPG-conf.ini' en secciones\n",
    "def config(archivo='PGToPG-conf.ini', seccion='pg_server'):\n",
    "    # Crear el parser y leer el archivo\n",
    "    parser = ConfigParser()\n",
    "    parser.read(archivo)\n",
    " \n",
    "    # Obtener la secci贸n de conexi贸n a la base de datos\n",
    "    result = {}\n",
    "    if parser.has_section(seccion):\n",
    "        params = parser.items(seccion)\n",
    "        for param in params:\n",
    "            result[param[0]] = param[1]\n",
    "        return result\n",
    "    else:\n",
    "        raise Exception('Seccion {0} no encontrada en el archivo {1}'.format(seccion, archivo))\n",
    "\n",
    "#params_pg_server = config() # Se extraen los parametros del servidor postgres de PGToPG-conf.ini\n",
    "ExtractDB_params = config('PGToPG-conf.ini','Extract_from_pg_server') # Se extraen los parametros de la base postgres desde la cual se extraeran los datos\n",
    "LoadDB_params = config('PGToPG-conf.ini','Load_to_pg_server') # Se extraen los parametros de la base postgres a la cual se cargaran los datos previamente extraidos\n",
    "# No usar mayusculas para el nombre de la base de datos postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 1: Data extraction to Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una conexion en 'engine' para utilizar SQLAlchemy\n",
    "dbConexionString = 'postgresql://'+ExtractDB_params['user']+':'+ExtractDB_params['password']+'@'+ExtractDB_params['host']+':'+ExtractDB_params['port']+'/' + ExtractDB_params['database']\n",
    "engine = al.create_engine(dbConexionString)\n",
    "\n",
    "\n",
    "# Definicion de dataframe 'tableNames' con los nombres de las tablas\n",
    "tableNames = sqlio.read_sql_query(\"SELECT table_name\\n\\tFROM information_schema.tables\\n\\tWHERE table_schema=\"+\"'\"+ExtractDB_params['schema_name']+\"'\"+\"\\n\\tAND table_type='BASE TABLE';\", engine)\n",
    "tablesToLoad = [\"actions\", \"roles\", \"role_action\", \"user_roles\"]\n",
    "print(tableNames)\n",
    "dbData = []\n",
    "selectQuery = \"SELECT * from \"\n",
    "\n",
    "# Iteracion en la que se carga 'dbData' con los datos de cada tabla de la BDD (un SELECT por tabla existente)\n",
    "for i in range(len(tableNames)):\n",
    "    currentTable = tableNames['table_name'][i]\n",
    "    dbData.append(sqlio.read_sql_query(selectQuery + ExtractDB_params['schema_name'] + '.' + currentTable, engine))\n",
    "    if (currentTable in tablesToLoad):\n",
    "        print(dbData[i])\n",
    "\n",
    "# Cerramos el engine de SQLAlchemy\n",
    "engine.dispose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 2: Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una conexion en 'engine' para utilizar SQLAlchemy\n",
    "dbConexionString = 'postgresql://'+LoadDB_params['user']+':'+LoadDB_params['password']+'@'+LoadDB_params['host']+':'+LoadDB_params['port']+'/' + LoadDB_params['database']\n",
    "engine = al.create_engine(dbConexionString)\n",
    "\n",
    "with engine.begin() as connection:\n",
    "    # Iteracion donde recorre cada dataframe en 'dbData' y carga los datos formateados de cada df a la tabla correspondiente en la nueva BDD\n",
    "    for i in range(len(dbData)):\n",
    "        if (tableNames['table_name'][i] in tablesToLoad):\n",
    "            dbData[i].to_sql(tableNames['table_name'][i], con=connection, if_exists=\"append\", index = False, schema=LoadDB_params['schema_name'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerramos el engine de SQLAlchemy\n",
    "connection.close()\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f1b688e5dc678ecae4edbf458b512dd7d49e79593819bf17fc264de6db80c5b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
