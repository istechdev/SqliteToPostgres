{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook para la conversión de db sqlite to pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sqlalchemy as al\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 0: Definición de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqliteDb = \"D:/BDD-Sqlite(V1)/app.db\"\n",
    "newPostgreSQLDbName = 'bddAutomatica' # No usar mayusculas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 1: Sqlite Dump File or dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establece la conexion con una BDD SQlite\n",
    "conn = sqlite3.connect(sqliteDb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de dataframe 'dbSchemaQueries' con sentencias SQL para la creacion del esquema de la BDD\n",
    "dbSchemaQueries = pd.read_sql(\"select sql from sqlite_master\", con=conn)\n",
    "dbSchemaQueries = dbSchemaQueries.mask(dbSchemaQueries.eq(None)).dropna()\n",
    "\n",
    "# Definicion de dataframe 'tableNames' con los nombres de las tablas\n",
    "tableNames = pd.read_sql(\"SELECT name FROM sqlite_master WHERE (type='table')\", con=conn)\n",
    "\n",
    "# Definicion de 'dbData', lista que contendra multiples dataframes, cada uno con los datos de una tabla de la BDD\n",
    "dbData = []\n",
    "selectQuery = \"SELECT * from \"\n",
    "\n",
    "# Iteracion en la que se carga 'dbData' con los datos de cada tabla de la BDD (un SELECT por tabla existente)\n",
    "for i in range(len(tableNames)):\n",
    "    currentTable = tableNames['name'][i]\n",
    "    dbData.append(pd.read_sql_query(selectQuery + currentTable, con=conn))\n",
    "\n",
    "\"\"\"selectQuery = \"SELECT * from \"\n",
    "tableName= tableNames['name'][1]\"\"\"\n",
    "\n",
    "# Cambia los datos de las columnas con identificadores a su tipo respectivo (boolean, timestamp, money, etc)\n",
    "for i in dbData:\n",
    "    for columnName in i.columns: \n",
    "        if \"(BL)\" in columnName:\n",
    "            i[columnName] = i[columnName].astype(bool)\n",
    "            #print(i[col_name])\n",
    "        elif \"date\" in columnName:\n",
    "            i[columnName] = pd.to_datetime(i[columnName])\n",
    "            #print(i[col_name])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 2: Dump file or dataframe parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de funcion 'boolCHECKDelete' (limpia una Query SQL eliminando los CHECKS booleanos que pueda tener)\n",
    "def boolCHECKDelete(query):\n",
    "\n",
    "    # Define una variable auxiliar para procesar la query recibida\n",
    "    parsedQuery = query\n",
    "\n",
    "    # Define un substring con todos los CHECK de la query\n",
    "    allChecks = parsedQuery[parsedQuery.index('\\tCHECK'):-1]\n",
    "\n",
    "    # Separa cada CHECK como un nuevo substring\n",
    "    allChecks = allChecks.split('\\n')\n",
    "\n",
    "    # Recorre todos los CHECK que posee la query, busca si existe el tag '(BL)' y borra los que los posean (boolean CHECKS utilizados en SQlite) \n",
    "    for i in range(len(allChecks)):\n",
    "        if '(BL)' in allChecks[i]:\n",
    "            parsedQuery = parsedQuery.replace('\\n'+allChecks[i], '')\n",
    "\n",
    "    # Chequea si existe una ',' en el final de la query y la elimina para mantener correcta la sintaxis de la misma\n",
    "    if ',' in parsedQuery[len(parsedQuery)-5:]:\n",
    "        parsedQuery = parsedQuery[:len(parsedQuery)-5] + '' + parsedQuery[len(parsedQuery)-5] + '\\n)'\n",
    "    return parsedQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test del funcionamiento de la funcion con una Query de prueba\n",
    "testQuery = dbSchemaQueries['sql'][9].replace('CHECK (\"is_manager(BL)\" IN (0, 1)),', 'CHECK (\"is_manager\" IN (10, 51)),')\n",
    "testQuery = testQuery.replace('CHECK (\"soft_delete(BL)\" IN (0, 1))', 'CHECK (\"soft_delete\" IN (110, 221))')\n",
    "testQuery = testQuery.replace('CHECK (\"is_admin(BL)\" IN (0, 1)),', 'CHECK (\"is_admin\" IN (0, 1)),')\n",
    "print(testQuery)\n",
    "print(boolCHECKDelete(testQuery))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parseo de todas las queries de la BDD SQlite almacenadas en el dataframe 'dbSchemaQueries'\n",
    "\n",
    "# Definicion de 'parsed_dbSchemaQueries', lista que contendra todas las queries parseadas\n",
    "parsed_dbSchemaQueries = []\n",
    "\n",
    "# Iteracion que recorre todo el dataframe, query a query.\n",
    "for i in dbSchemaQueries.index:\n",
    "\n",
    "    # Define una variable auxiliar para procesar la query actual\n",
    "    currentQuery = dbSchemaQueries['sql'][i]\n",
    "    \n",
    "    # Reemplaza los campos DATETIME con TIMESTAMP para el pasaje a PosgreSQL\n",
    "    currentQuery = currentQuery.replace('DATETIME', 'TIMESTAMP')\n",
    "\n",
    "    # Sentencia ocasional debido al fallo en un campo de la tabla purchase, donde la longitud de los datos almacenados supera la asignada al campo\n",
    "    currentQuery = currentQuery.replace('VARCHAR(16)', 'VARCHAR(32)')\n",
    "\n",
    "    # Se verifica que la query posea CHECKS, en caso de tenerlos, ejecuta 'boolCHECKDelete' en la query actual\n",
    "    if(currentQuery.find('CHECK') != -1):\n",
    "        currentQuery = boolCHECKDelete(currentQuery)\n",
    "\n",
    "    # Añade la query parseada a la lista\n",
    "    parsed_dbSchemaQueries.append(currentQuery)\n",
    "\n",
    "# Impresion por pantalla de las queries parseadas\n",
    "for i in range(len(parsed_dbSchemaQueries)):\n",
    "    print(parsed_dbSchemaQueries[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all CHECKS.\n",
    "parsed_dbSchemaQueries_2 = []\n",
    "userCount = 1\n",
    "for i in dbSchemaQueries.index:\n",
    "    aux = dbSchemaQueries['sql'][i]\n",
    "    aux = aux.replace('DATETIME', 'TIMESTAMP')\n",
    "\n",
    "    # Conditions for table named \"user\".\n",
    "    \"\"\"aux = aux.replace('CREATE TABLE user', 'CREATE TABLE \"user\"')\n",
    "    aux = aux.replace('CREATE TABLE \"user\"_', 'CREATE TABLE user_')\n",
    "    aux = aux.replace('ON user', 'ON \"user\"')\n",
    "    aux = aux.replace('ON \"user\"_', 'ON user_')\n",
    "    aux = aux.replace('REFERENCES user', 'REFERENCES \"user\"')\n",
    "    aux = aux.replace('REFERENCES \"user\"_', 'REFERENCES user_')\"\"\"\n",
    "\n",
    "    aux = aux.replace('VARCHAR(16)', 'VARCHAR(32)')\n",
    "    if(aux.find('CHECK') != -1):\n",
    "        a = aux.replace('CHECK', '@')\n",
    "        b = a.replace(a[a.index('@'):len(a)-1], '')\n",
    "        temp = list(b)\n",
    "        temp[len(temp)-5] = ''\n",
    "        aux = \"\".join(temp)\n",
    "    parsed_dbSchemaQueries_2.append(aux)\n",
    "for i in range(len(parsed_dbSchemaQueries_2)):\n",
    "    print(parsed_dbSchemaQueries_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsed Querys with all checks deleted and with only boolean checks deleted lenght test.\n",
    "if(len(parsed_dbSchemaQueries) == len(parsed_dbSchemaQueries_2)):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 3: Dump file to pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraccion de prametros del archivo 'pg.ini'\n",
    "def config(archivo='pg.ini', seccion='postgresql'):\n",
    "    # Crear el parser y leer el archivo\n",
    "    parser = ConfigParser()\n",
    "    parser.read(archivo)\n",
    " \n",
    "    # Obtener la sección de conexión a la base de datos\n",
    "    db = {}\n",
    "    if parser.has_section(seccion):\n",
    "        params = parser.items(seccion)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "        return db\n",
    "    else:\n",
    "        raise Exception('Secccion {0} no encontrada en el archivo {1}'.format(seccion, archivo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 4: Conexión al servidor de bases de datos PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conectar():\n",
    "    \"\"\" Conexión al servidor de bases de datos PostgreSQL \"\"\"\n",
    "    conexion = None\n",
    "    try:\n",
    "        # Lectura de los parámetros de conexion\n",
    "        params = config()\n",
    " \n",
    "        # Conexion al servidor de PostgreSQL\n",
    "        print('Conectando a la base de datos PostgreSQL...')\n",
    "        print(params)\n",
    "        conexion = psycopg2.connect(**params)\n",
    "        conexion.autocommit = True\n",
    " \n",
    "        # creación del cursor\n",
    "        cur = conexion.cursor()\n",
    "        \n",
    "        # Ejecución de una consulta con la version de PostgreSQL\n",
    "        print('La version de PostgreSQL es la:')\n",
    "        cur.execute('SELECT version()')\n",
    " \n",
    "        # Ahora mostramos la version\n",
    "        version = cur.fetchone()\n",
    "        print(version)\n",
    "\n",
    "        # Cierre de la comunicación con PostgreSQL\n",
    "        cur.close()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conexion is not None:\n",
    "            \"\"\"conexion.close()\n",
    "            print('Conexión finalizada.')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conectar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 5: Creación de base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el cursor con el objeto conexion\n",
    "params = config()\n",
    "conexion = psycopg2.connect(**params)\n",
    "conexion.autocommit = True\n",
    "cur = conexion.cursor()\n",
    "\n",
    "# creamos la nueva BDD utilizando el cursor\n",
    "createDBQuery = 'CREATE DATABASE ' + newPostgreSQLDbName\n",
    "cur.execute(createDBQuery)\n",
    "\n",
    "newDBparams = config()\n",
    "newDBparams['database'] = newPostgreSQLDbName\n",
    "\n",
    "# Cerramos la conexión\n",
    "conexion.commit()\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 6: Carga del esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el cursor con el objeto conexion\n",
    "conexion = psycopg2.connect(**newDBparams)\n",
    "conexion.autocommit = True\n",
    "cur = conexion.cursor()\n",
    "\n",
    "# iteracion en la cual el cursor ejecuta todas las queries previamente parseadas una a una. (Crea las tablas en la nueva BDD PostgreSQL)\n",
    "for i in range(len(parsed_dbSchemaQueries)):\n",
    "    cur.execute(parsed_dbSchemaQueries[i])\n",
    "\n",
    "# Cerramos la conexión\n",
    "conexion.commit()\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloque 6: Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una conexion en 'engine' para utilizar SQLAlchemy\n",
    "dbConexionString = 'postgresql://gdeluca:gdeluca@192.168.1.105:5432/' + newPostgreSQLDbName\n",
    "engine = al.create_engine(dbConexionString)\n",
    "\n",
    "# Iteracion donde recorre cada dataframe en 'dbData' y carga los datos formateados de cada df a la tabla correspondiente en la nueva BDD\n",
    "for i in range(len(dbData)):\n",
    "    dbData[i].to_sql(tableNames['name'][i], con=engine, if_exists=\"append\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f1b688e5dc678ecae4edbf458b512dd7d49e79593819bf17fc264de6db80c5b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
